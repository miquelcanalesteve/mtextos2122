
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Análisis semántico vectorial &#8212; Minería de Textos</title>
    
  <link href="_static/css/theme.css" rel="stylesheet">
  <link href="_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/sphinx-book-theme.css?digest=84ace793992934648b4de8eed757e5a2" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/estilos.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.9d8b4a8b9bb19db25eeaddc40d639ba2.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Técnicas para la minería de textos" href="bloque2.html" />
    <link rel="prev" title="Fundamentos de PLN. Práctica 2. Análisis semántico." href="bloque1_Practica2.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<div class="col-12 col-md-3 bd-sidebar site-navigation " id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo-master-ca.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Minería de Textos</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="intro.html">
   Materiales de Minería de Textos
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="bloque1.html">
   Introducción a la minería de textos
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="bloque1_1Introduccion.html">
     Minería de textos y procesamiento del lenguaje natural.
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="bloque1_2CategorialSintactico.html">
     Análisis categorial y sintáctico
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="bloque1_Practica1.html">
     Fundamentos de PLN. Práctica 1.
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="bloque1_3AnalisisSemantico.html">
     Análisis semántico
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="bloque1_Practica2.html">
     Fundamentos de PLN. Práctica 2. Análisis semántico.
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Análisis semántico vectorial
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="bloque2.html">
   Técnicas para la minería de textos
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="bloque2_historia.html">
     Revisión histórica
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="bloque3.html">
   Aplicaciones de la minería de textos
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="bloque3_t1_aplicaciones.html">
     T1. Aplicaciones generales
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="bloque3_t2_subaplicaciones-benchmarks.html">
     T2. Aplicaciones específicas y Benchmacks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="bloque3_t2.1_analisis_sentimientos.html">
     T2.1. Aplicaciones específicas. Análisis de Sentimientos
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="bloque3_t3.1_metricas.html">
     T3. Métricas de Evaluación
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="bloque3_t4_huggingface.html">
     T4. Centralización de datasets y modelos: Huggingface
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="bloque3_t5_automl.html">
     T5. Auto Machine Learning(AutoML)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="bloque3_t5.1_autogoal.html">
     T5.1. AutoGOAL
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="bloque3_p1_SA-Pipeline-Reviews.html">
     P1.1. Pipeline simple
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="bloque3_p2_SA-Transformers-Basic.html">
     P1.2. APIs Transformers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="bloque3_p3_SA-Transformers-Training-FineTuning.html">
     P2. Reajustar modelos Transformers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="bloque3_p4_SA-Transformers-Training-Custom.html">
     P3. Composición de vectores de características
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="bloque3_p5-SA-Ensemble.html">
     P4. Ensemble de pipelines
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="bloque3_p6_SA-AutoGOAL.html">
     P5. Auto Machine Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="bloque3_ev.html">
     Ev. Evaluación del bloque 3
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="content.html">
   Content in Jupyter Book
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="markdown.html">
     Markdown Files
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="notebooks.html">
     Content with notebooks
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<!-- This is an invisible pixel that we watch to see if we've scrolled. -->
<div class="sbt-scroll-pixel-helper"></div>
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            <div class="topbar-left">
                
                <label class="nav-toggle-button" for="__navigation">
                    <div class="visually-hidden">Toggle navigation</div>
                    <i class="fas fa-bars"></i>
                </label>
                
            </div>
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/bloque1_4AnalisisSemanticoVectorial.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#indice">
   Índice
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#lectura-obligatoria">
   Lectura obligatoria:
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#objetivos">
   Objetivos
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduccion">
   Introducción
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#origen">
   Origen
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#fundamentos-linguisticos">
   Fundamentos lingüísticos
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#representacion-vectorial-del-significado">
   Representación vectorial del significado
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#representacion-del-contexto">
     Representación del contexto
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#representacion-de-las-palabras">
     Representación de las palabras
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#calculo-de-los-valores-o-pesos">
     Cálculo de los valores o pesos
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#tf-idf-term-frequency-inverse-document-frequency-sparck-jones-1972">
       TF/IDF:
       <em>
        term frequency / inverse document frequency
       </em>
       (Sparck Jones, 1972)
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#matriz-dispersa-y-matriz-densa">
       Matriz dispersa y matriz densa
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#interpretacion-semantica-distancia-y-similitud">
   Interpretación semántica: distancia y similitud.
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#conclusiones">
     Conclusiones
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#situacion-actual">
   Situación actual
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#herramientas-y-recursos">
   Herramientas y recursos
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#apendice-estudio-de-caso">
   Apéndice. Estudio de caso.
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bibliografia">
   Bibliografía
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Análisis semántico vectorial</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#indice">
   Índice
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#lectura-obligatoria">
   Lectura obligatoria:
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#objetivos">
   Objetivos
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduccion">
   Introducción
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#origen">
   Origen
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#fundamentos-linguisticos">
   Fundamentos lingüísticos
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#representacion-vectorial-del-significado">
   Representación vectorial del significado
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#representacion-del-contexto">
     Representación del contexto
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#representacion-de-las-palabras">
     Representación de las palabras
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#calculo-de-los-valores-o-pesos">
     Cálculo de los valores o pesos
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#tf-idf-term-frequency-inverse-document-frequency-sparck-jones-1972">
       TF/IDF:
       <em>
        term frequency / inverse document frequency
       </em>
       (Sparck Jones, 1972)
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#matriz-dispersa-y-matriz-densa">
       Matriz dispersa y matriz densa
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#interpretacion-semantica-distancia-y-similitud">
   Interpretación semántica: distancia y similitud.
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#conclusiones">
     Conclusiones
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#situacion-actual">
   Situación actual
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#herramientas-y-recursos">
   Herramientas y recursos
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#apendice-estudio-de-caso">
   Apéndice. Estudio de caso.
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bibliografia">
   Bibliografía
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="section" id="analisis-semantico-vectorial">
<span id="label-semantica-vectorial"></span><h1>Análisis semántico vectorial<a class="headerlink" href="#analisis-semantico-vectorial" title="Permalink to this headline">¶</a></h1>
<div class="section" id="indice">
<h2>Índice<a class="headerlink" href="#indice" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Introducción a los modelos semánticos vectoriales.</p></li>
<li><p>Estudio de caso: <em>topic modeling</em>.</p></li>
</ul>
</div>
<div class="section" id="lectura-obligatoria">
<h2>Lectura obligatoria:<a class="headerlink" href="#lectura-obligatoria" title="Permalink to this headline">¶</a></h2>
<p>Peter D. Turney y Patrick Pantel (2010) “From Frequency to Meaning: Vector Space Models of Semantics” en <em>Journal of Artificial Intelligence  Research</em>, 37, págs. 141-188.  DOI: https://doi.org/10.1613/jair.2934</p>
<p><a class="reference external" href="https://www.jair.org/index.php/jair/article/view/10640">https://www.jair.org/index.php/jair/article/view/10640</a></p>
<p><a class="reference external" href="https://www.jair.org/index.php/jair/article/view/10640/25440">https://www.jair.org/index.php/jair/article/view/10640/25440</a></p>
</div>
<div class="section" id="objetivos">
<h2>Objetivos<a class="headerlink" href="#objetivos" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Definir semántica distribucional.</p></li>
<li><p>Comprender cómo se representa el significado mediante vectores.</p></li>
<li><p>Conocer los principales factores que determinan la representación vectorial.</p></li>
<li><p>Conocer los conceptos de distancia y similitud, y medidas básicas.</p></li>
</ul>
</div>
<div class="section" id="introduccion">
<h2>Introducción<a class="headerlink" href="#introduccion" title="Permalink to this headline">¶</a></h2>
<p>Semántica vectorial: Nueva aproximación <strong>formal</strong> a la <strong>semántica</strong> de las lenguas naturales.</p>
<ul class="simple">
<li><p>Formalismo:</p>
<ul>
<li><p>Espacios vectoriales y álgebra lineal.</p></li>
<li><p><em>Quantum semantics</em>: similar al caso de la mecánica cuántica matricial de
<a class="reference external" href="https://es.wikipedia.org/wiki/Werner_Heisenberg">Heisenberg</a>.</p></li>
<li><p>Geometría: relaciones de <em>similitud semántica</em> basadas en
<em>distancias</em> (Widdows 2004).</p></li>
</ul>
</li>
<li><p>Semántica contextual y distribucional (basada en el uso).</p>
<ul>
<li><p>vs. unidad atómica (lógica formal): “casa”</p></li>
<li><p>vs. definición (semántica léxica).</p></li>
<li><p>vs. relaciones léxicas paradigmáticas (WordNet <em>synset</em>).</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="origen">
<h2>Origen<a class="headerlink" href="#origen" title="Permalink to this headline">¶</a></h2>
<p><strong>Recuperación de información</strong> (<em>Information Retrieval</em>): ej.
buscadores de internet.</p>
<ul class="simple">
<li><p>Tarea: dada una <em>query</em> (uno o más términos), obtener una lista de
documentos ordenada por relevancia.</p></li>
<li><p>Matriz Término - Documento.</p></li>
<li><p>Cada documento se representa como una “bolsa de palabras” (<em>bag of
words</em>): conjunto de palabras sin relación entre ellas.</p></li>
</ul>
<p>Matriz Término - Documento</p>
<ul class="simple">
<li><p>Columnas: documentos.</p></li>
<li><p>Líneas: términos</p></li>
<li><p>Valores: frecuencia del término en cada documento.</p></li>
</ul>
<p>Con dos documentos:</p>
<p>doc1 <span class="math notranslate nohighlight">\(= \{casa, madera, mesa\}\)</span></p>
<p>doc2 <span class="math notranslate nohighlight">\(= \{papel, rama, madera\}\)</span></p>
<hr class="docutils" />
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>        Doc 1   Doc 2   \...   Doc $n$
casa      1       0     \...    \...
madera    1       1     \...    \...
mesa      1       0     \...    \...
papel     0       1     \...    \...
rama      0       1     \...    \...
</pre></div>
</div>
<hr class="docutils" />
<p>Matriz Término-Documento</p>
</div>
<div class="section" id="fundamentos-linguisticos">
<h2>Fundamentos lingüísticos<a class="headerlink" href="#fundamentos-linguisticos" title="Permalink to this headline">¶</a></h2>
<p>Los modelos semánticos vectoriales asumen básicamente tres propuestas teóricas (Clarke 2011):</p>
<ol>
<li><p>La idea de Wittgenstein (1953) de “meaning just is use”
(Wittgenstein 1953);</p></li>
<li><p>El concepto de <em>collocation</em> de Firth (1957) y su idea
de que</p>
<blockquote>
<div><p>“you shall know a word by the company it keeps”;</p>
</div></blockquote>
</li>
<li><p>La hipótesis distribucional de Harris (1968):</p>
<blockquote>
<div><p>“words will occur in similar contexts if and only if they have similar meanings”.</p>
</div></blockquote>
</li>
</ol>
<p>Todo ello se engloba dentro del concepto de “significado
distribucional”.</p>
</div>
<div class="section" id="representacion-vectorial-del-significado">
<h2>Representación vectorial del significado<a class="headerlink" href="#representacion-vectorial-del-significado" title="Permalink to this headline">¶</a></h2>
<p>Un vector captura la semántica contextual/distribucional de la palabra (token o lema) al representar el número de veces (frecuencia) que la palabra aparece en cada contexto (documento).</p>
<hr class="docutils" />
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>       doc1   doc2
car     7      6
taxi    5      6
train   6      1
</pre></div>
</div>
<hr class="docutils" />
<p><span class="math notranslate nohighlight">\(car = (7,6)\)</span><br />
<span class="math notranslate nohighlight">\(taxi = (5,6)\)</span><br />
<span class="math notranslate nohighlight">\(train = (6,1)\)</span></p>
<p>Representación en un espacio euclídeo (plano o lineal). Representación mediante coordenadas cartesianas. Los valores del vector se proyecta en los ejes de coordenadas.</p>
<p>Espacios <span class="math notranslate nohighlight">\(n\)</span>-dimesionales o multidimensionales: para representar el significado de una palabra, las dimensiones (coordenadas) son los contextos en los aparece la palabra (en este caso, documentos).</p>
<p>Plano cartesiano (dos dimensiones):</p>
<p><img alt="cartesanio1" src="_images/cartesiano_1.png" /></p>
<p><img alt="cartesanio2" src="_images/cartesiano_2.png" /></p>
<hr class="docutils" />
<p>La representación del significado varía según se diseñe el espacio vectorial.</p>
<p>Factores relevantes:</p>
<ul class="simple">
<li><p>Representación del contexto (dimensiones)</p></li>
<li><p>Representación de las palabras (filas)</p></li>
<li><p>Valores o pesos de cada palabra en cada contexto.</p></li>
</ul>
<div class="section" id="representacion-del-contexto">
<h3>Representación del contexto<a class="headerlink" href="#representacion-del-contexto" title="Permalink to this headline">¶</a></h3>
<p>Cada uno de los contextos donde pueda aparece una palabra será una
dimensión.</p>
<p>¿Cómo delimitar el contexto?</p>
<p>Matriz Término-Documento. Modelo de representación propio de Recuperación de Información. El contexto es todo el texto o documento donde aparece la palabra. El concepto de contexto muy laxo, pero es eficiente. No tiene en cuenta las relaciones entre palabras y puede haber contextos de difererente tamaño.</p>
<p>Esta idea se puede llevar a contextos con una mayor motivación lingüística:</p>
<ul class="simple">
<li><p>oración,</p></li>
<li><p>párrafo u otra unidad textual,</p></li>
<li><p>capítulos,</p></li>
<li><p>etc.</p></li>
</ul>
<p>Matriz de co-ocurrencias: Matriz Término-Término: número de veces que dos palabras aparecen en los mismos contexto.</p>
<p>Contexto más pequeño y motivado lingüísticamente: oración, relación sintáctica, ventana de palabras u oraciones (párrafo deslizante), etc.</p>
<hr class="docutils" />
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>       red   readable   blue
car     5       0        1
book    3       6        0
</pre></div>
</div>
<hr class="docutils" />
<p>Ejemplo de matriz con motivación lingüística fuerte: matriz <em>Pair-Pattern</em> (TurneyPantel 2010): Las filas son parejas de palabras (“carpenter:wood”), las columnas son relaciones entre palabras co-ocurrentes (“X cut Y”).</p>
<p>Y por aquí se pueden definir variantes. En todos estos casos, lo que cambia es cómo se representa el contexto.</p>
</div>
<div class="section" id="representacion-de-las-palabras">
<h3>Representación de las palabras<a class="headerlink" href="#representacion-de-las-palabras" title="Permalink to this headline">¶</a></h3>
<p>Según vimos en sesiones anteriores:</p>
<ul class="simple">
<li><p>Token</p></li>
<li><p>Raíz (stem)</p></li>
<li><p>Lemas</p></li>
<li><p>Lema + Categoría Gramatical</p></li>
<li><p>Filtro <em>stopwords</em></p></li>
<li><p>Sólo nombres (o sólo verbos, o sólo adjetivos, etc.)</p></li>
<li><p>Lema + Función sintáctica</p></li>
<li><p>etc.</p></li>
</ul>
<p>Requieren pre-proceso del corpus con técnicas de PLN vistas con anterioridad.</p>
</div>
<div class="section" id="calculo-de-los-valores-o-pesos">
<h3>Cálculo de los valores o pesos<a class="headerlink" href="#calculo-de-los-valores-o-pesos" title="Permalink to this headline">¶</a></h3>
<p>Representación cuantitativa de la relevancia (peso) que tiene la palabra en cada contexto.</p>
<p>Frecuencias simples y relativas: número de veces que la palabra aparece en el contexto, normalizado por el tamaño del contexto.</p>
<p>Problemas:</p>
<ul class="simple">
<li><p>Depende del tamaño del contexto.</p></li>
<li><p>No discrimina la importancia real de cada palabra en el contexto.</p></li>
<li><p>El <em>[hapax legomenon]</em>(https://en.wikipedia.org/wiki/Hapax_legomenon)</p></li>
</ul>
<div class="section" id="tf-idf-term-frequency-inverse-document-frequency-sparck-jones-1972">
<h4>TF/IDF: <em>term frequency / inverse document frequency</em> (Sparck Jones, 1972)<a class="headerlink" href="#tf-idf-term-frequency-inverse-document-frequency-sparck-jones-1972" title="Permalink to this headline">¶</a></h4>
<p>Idea intuitiva: palabras de uso común que aparecen con alta frecuencia en muchos contextos no son discriminativas ni relevantes. TF/IDF intenta dar más peso a las palabras específicas de cada documento.</p>
<ul class="simple">
<li><p><em>Term frequency</em> (tf): frecuencia de una palabra en un documento dado.</p></li>
<li><p><em>Document frequency</em> (df): cantidad de documentos donde aparece una determinada palabra.</p></li>
<li><p><em>Inverse document frequency</em> (idf): <span class="math notranslate nohighlight">\(N/df\)</span> donde N = cantidad total de documentos.</p></li>
</ul>
<p>Así, el valor tf-idf (<span class="math notranslate nohighlight">\(w\)</span>) de una palabra <span class="math notranslate nohighlight">\(t\)</span> en un documento <span class="math notranslate nohighlight">\(d\)</span> es:</p>
<div class="math notranslate nohighlight">
\[w_t,_d = tf_t,_d · idf_t\]</div>
</div>
<div class="section" id="matriz-dispersa-y-matriz-densa">
<h4>Matriz dispersa y matriz densa<a class="headerlink" href="#matriz-dispersa-y-matriz-densa" title="Permalink to this headline">¶</a></h4>
<p>Dadas las caracterísiticas de los idiomas, este tipo de matrices son siempre muy dispersas, en las que la mayoría de los valores con cero.</p>
<blockquote>
<div><p><em>Sparse matrix</em>: la mayoría de los valores son ceros.</p>
</div></blockquote>
<p>Para solucionar esto se reduce la dimensionalidad de la matriz, generando así  matrices densas (<em>dense matrix</em>) donde la mayoría de los valores no son ceros pero manteniendo las relaciones semánticas entre las palabras (los valores semánticos).</p>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Latent_semantic_analysis"><em>Latent semantic analysis</em></a>: descomposición de la matriz dispesar en valores singulares (<a class="reference external" href="https://en.wikipedia.org/wiki/Singular_value_decomposition"><em>singular value decomposition</em></a>), generando una matriz densa de 300 dimensiones. Se considera que mantiene relaciones semánticas “latentes”. Origen de los <em>word embeddings</em> que veréis en próximos temas.</p>
</div>
</div>
</div>
<div class="section" id="interpretacion-semantica-distancia-y-similitud">
<h2>Interpretación semántica: distancia y similitud.<a class="headerlink" href="#interpretacion-semantica-distancia-y-similitud" title="Permalink to this headline">¶</a></h2>
<p>La interpretación en esta aproximación vectorial a la semántica distribucional se realiza por relaciones de similitud entre palabras o documentos. La similitud se calcular según la distancia entre los vectores en el espacio vectorial: a menor distancia entre vectores, mayor similitud semántica.</p>
<p>Así, desde un punto de vista lingüístico, dos vectores (de palabras) serán similares en la medida que tengan valores relevantes en los mismos contextos.</p>
<p>Cualquier aplicación de semántica vectorial debe pensarse en términos de
similitudes (entre palabras, grupos de palabras, textos, etc.).</p>
<p>Hay diferentes medidas. Las más utilizada es la similitud del coseno, que mide el ángulo entre dos vectores ambos con origen en 0,0.</p>
<div class="math notranslate nohighlight">
\[cos(a,b) = \frac{a · b}{||a|| ||b||}\]</div>
<p><img alt="cartesanio2" src="_images/cartesiano_2.png" />{height=”10cm”}</p>
<div class="section" id="conclusiones">
<h3>Conclusiones<a class="headerlink" href="#conclusiones" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Representación formal del significado distribucional.</p></li>
<li><p>El significado se represente mediante vectores dentro de un espacio semántica vectorial.</p></li>
<li><p>El vector está formado por el peso de la palabra en cada uno de los contextos (documentos, oraciones, etc.)</p></li>
<li><p>El proceso de interpretación se basa en la distancia entre vectores: similitud.</p></li>
</ul>
</div>
</div>
<div class="section" id="situacion-actual">
<h2>Situación actual<a class="headerlink" href="#situacion-actual" title="Permalink to this headline">¶</a></h2>
<p>De aquí derivan los <em>word embeddings</em> que, junto con las redes neuronales, han revolucionado el campo del PLN. De todo esto os hablará el prof. Juan Antonio Pérez Ortiz en las próximas sesiones.</p>
</div>
<div class="section" id="herramientas-y-recursos">
<h2>Herramientas y recursos<a class="headerlink" href="#herramientas-y-recursos" title="Permalink to this headline">¶</a></h2>
<p>Para crear espacios vectoriales y calcular similitudes:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://radimrehurek.com/gensim/">GENSIM</a></p></li>
<li><p><a class="reference external" href="http://www.nltk.org/">NLTK</a></p></li>
<li><p><a class="reference external" href="http://www.clips.ua.ac.be/pattern">Pattern</a></p></li>
<li><p><a class="reference external" href="https://spacy.io/">SpaCy</a></p></li>
</ul>
</div>
<div class="section" id="apendice-estudio-de-caso">
<h2>Apéndice. Estudio de caso.<a class="headerlink" href="#apendice-estudio-de-caso" title="Permalink to this headline">¶</a></h2>
<p>Extracción de <em>topics</em> con Topic Modeling.</p>
</div>
<div class="section" id="bibliografia">
<h2>Bibliografía<a class="headerlink" href="#bibliografia" title="Permalink to this headline">¶</a></h2>
<p>David M. Blei (2012) “Probabilistic topic models” en <em>Communications of the ACM</em> vol. 55 (4), April 2012. Doi:10.1145/2133806.2133826
<a class="reference external" href="https://dl.acm.org/doi/10.1145/2133806.2133826">https://dl.acm.org/doi/10.1145/2133806.2133826</a></p>
<p>Juravsky y Martin (2020) <em>Speech and Language Processing</em>. https://web.stanford.edu/~jurafsky/slp3/
(Caps. 12-14)</p>
<p>Ferrone Lorenzo y Zanzotto Fabio Massimo (2020) “Symbolic, Distributed, and Distributional Representations for Natural Language Processing in the Era of Deep Learning: A Survey” en <em>Frontiers in Robotics and AI</em>, pags, 153. DOI 10.3389/frobt.2019.00153
<a class="reference external" href="https://www.frontiersin.org/article/10.3389/frobt.2019.00153">https://www.frontiersin.org/article/10.3389/frobt.2019.00153</a></p>
<p>Navarro Colorado, Borja (2021) “Sistemas de anotación semántica para corpus de español” en Giovanni Parodi, Pascual Cantos &amp; Lewis Howe (Editores) <em>The Routledge Handbook of Spanish Corpus Linguistics</em> Routledge (en prensa).</p>
<p>D. Widdows (2004) <em>Geometry and meaning</em>, CSLI.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="bloque1_Practica2.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Fundamentos de PLN. Práctica 2. Análisis semántico.</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="bloque2.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Técnicas para la minería de textos</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Universitat d'Alacant<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>