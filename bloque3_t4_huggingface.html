
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>T4. Centralizaci√≥n de datasets y modelos: Huggingface &#8212; Miner√≠a de Textos</title>
    
  <link href="_static/css/theme.css" rel="stylesheet">
  <link href="_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/sphinx-book-theme.css?digest=84ace793992934648b4de8eed757e5a2" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/estilos.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.9d8b4a8b9bb19db25eeaddc40d639ba2.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<div class="col-12 col-md-3 bd-sidebar site-navigation " id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo-master-ca.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Miner√≠a de Textos</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="intro.html">
   Materiales de Miner√≠a de Textos
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="bloque1.html">
   Introducci√≥n a la miner√≠a de textos
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="bloque1_1Introduccion.html">
     Miner√≠a de textos y procesamiento del lenguaje natural.
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="bloque1_2CategorialSintactico.html">
     An√°lisis categorial y sint√°ctico
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="bloque1_Practica1.html">
     Fundamentos de PLN. Pr√°ctica 1.
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="bloque1_3AnalisisSemantico.html">
     An√°lisis sem√°ntico
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="bloque1_Practica2.html">
     Fundamentos de PLN. Pr√°ctica 2. An√°lisis sem√°ntico.
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="bloque1_4AnalisisSemanticoVectorial.html">
     An√°lisis sem√°ntico vectorial
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="bloque2.html">
   T√©cnicas para la miner√≠a de textos
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="bloque2_historia.html">
     Revisi√≥n hist√≥rica
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque3.html">
   Aplicaciones de la miner√≠a de textos
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="content.html">
   Content in Jupyter Book
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="markdown.html">
     Markdown Files
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="notebooks.html">
     Content with notebooks
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<!-- This is an invisible pixel that we watch to see if we've scrolled. -->
<div class="sbt-scroll-pixel-helper"></div>
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            <div class="topbar-left">
                
                <label class="nav-toggle-button" for="__navigation">
                    <div class="visually-hidden">Toggle navigation</div>
                    <i class="fas fa-bars"></i>
                </label>
                
            </div>
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/bloque3_t4_huggingface.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduccion">
   Introducci√≥n
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#repositorio-de-datasets">
   Repositorio de Datasets
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#listar-datasets-disponibles-en-el-repositorio">
     Listar datasets disponibles en el repositorio
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#como-cargar-datasets">
     ¬øC√≥mo cargar datasets?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#categorias-tareas-e-idiomas-de-datasets">
     Categor√≠as, tareas e idiomas de datasets
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#repositorio-de-modelos-pre-entrenados">
   Repositorio de Modelos pre-entrenados
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#listado-de-pipelines">
     Listado de Pipelines
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#como-buscar-y-reutilizar-modelos-pre-entrenados-en-la-plataforma">
     ¬øC√≥mo buscar y reutilizar modelos pre-entrenados en la plataforma?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#configuraciones-de-modelos-trasnformers">
     Configuraciones de modelos trasnformers
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bibliografia">
   Bibliograf√≠a
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>T4. Centralizaci√≥n de datasets y modelos: Huggingface</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduccion">
   Introducci√≥n
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#repositorio-de-datasets">
   Repositorio de Datasets
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#listar-datasets-disponibles-en-el-repositorio">
     Listar datasets disponibles en el repositorio
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#como-cargar-datasets">
     ¬øC√≥mo cargar datasets?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#categorias-tareas-e-idiomas-de-datasets">
     Categor√≠as, tareas e idiomas de datasets
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#repositorio-de-modelos-pre-entrenados">
   Repositorio de Modelos pre-entrenados
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#listado-de-pipelines">
     Listado de Pipelines
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#como-buscar-y-reutilizar-modelos-pre-entrenados-en-la-plataforma">
     ¬øC√≥mo buscar y reutilizar modelos pre-entrenados en la plataforma?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#configuraciones-de-modelos-trasnformers">
     Configuraciones de modelos trasnformers
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bibliografia">
   Bibliograf√≠a
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="section" id="t4-centralizacion-de-datasets-y-modelos-huggingface">
<h1>T4. Centralizaci√≥n de datasets y modelos: Huggingface<a class="headerlink" href="#t4-centralizacion-de-datasets-y-modelos-huggingface" title="Permalink to this headline">¬∂</a></h1>
<p>Contenidos:</p>
<ul class="simple">
<li><p><a class="reference external" href="#introduccion">Introducci√≥n</a></p></li>
<li><p><a class="reference external" href="#repositorio-de-datasets">Repositorio de Datasets</a></p></li>
<li><p><a class="reference external" href="#repositorio-de-modelos-pre-entrenados">Repositorio de Modelos pre-entrenados</a></p></li>
</ul>
<div class="section" id="introduccion">
<h2>Introducci√≥n<a class="headerlink" href="#introduccion" title="Permalink to this headline">¬∂</a></h2>
<p>Huggingface.co una compa√±√≠a centrada en el PLN la cual ha desarrollado las <a class="reference external" href="https://huggingface.co/transformers/"><strong>librer√≠as Transformers</strong></a>, <strong>centralizado datasets</strong> y ha <strong>creado modelos de aprendizaje pre-entrenados</strong> disponibles a trav√©s de sus librer√≠as de programaci√≥n.
Las librer√≠as de Huggingface actualmente dan soporte a empresas muy importantes del mercado tecnol√≥gico. Ver <a class="reference external" href="https://huggingface.co/">https://huggingface.co/</a>.</p>
</div>
<div class="section" id="repositorio-de-datasets">
<h2>Repositorio de Datasets<a class="headerlink" href="#repositorio-de-datasets" title="Permalink to this headline">¬∂</a></h2>
<p>Proporciona conjuntos de datos para muchas tareas de PLN como clasificaci√≥n de texto, respuesta a preguntas, modelado de lenguaje, etc.<br />
Instalaci√≥n de librer√≠a de manipulaci√≥n de datasets
Para la <strong>instalaci√≥n</strong> de la librer√≠a de manipulaci√≥n de datasets se debe ejecutar la siguiente instrucci√≥n pip:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">pip</span> <span class="n">install</span> <span class="n">datasets</span>
</pre></div>
</div>
<p>Para asegurarnos de que Transformers dataset se ha instalado correctamente es necesario ejecutar la siguiente instrucci√≥n:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">python</span> <span class="o">-</span><span class="n">c</span> <span class="s2">&quot;from datasets import load_dataset; print(load_dataset(&#39;squad&#39;, split=&#39;train&#39;)[0])&quot;</span>

</pre></div>
</div>
<p>Esta instrucci√≥n debe descargar la versi√≥n 1 del conjunto de datos de respuesta a preguntas de Stanford, cargar su divisi√≥n de entrenamiento e imprimir el primer ejemplo de entrenamiento de la siguiente manera:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s1">&#39;id&#39;</span><span class="p">:</span> <span class="s1">&#39;5733be284776f41900661182&#39;</span><span class="p">,</span> <span class="s1">&#39;title&#39;</span><span class="p">:</span> <span class="s1">&#39;University_of_Notre_Dame&#39;</span><span class="p">,</span> <span class="s1">&#39;context&#39;</span><span class="p">:</span> <span class="s1">&#39;Architecturally, the school has a Catholic character. Atop the Main Building</span><span class="se">\&#39;</span><span class="s1">s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend &quot;Venite Ad Me Omnes&quot;...&#39;</span><span class="p">,</span> <span class="s1">&#39;question&#39;</span><span class="p">:</span> <span class="s1">&#39;To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?&#39;</span><span class="p">,</span> <span class="s1">&#39;answers&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;text&#39;</span><span class="p">:</span> <span class="n">array</span><span class="p">([</span><span class="s1">&#39;Saint Bernadette Soubirous&#39;</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span><span class="p">),</span> <span class="s1">&#39;answer_start&#39;</span><span class="p">:</span> <span class="n">array</span><span class="p">([</span><span class="mi">515</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">int32</span><span class="p">)}}</span>
</pre></div>
</div>
<div class="section" id="listar-datasets-disponibles-en-el-repositorio">
<h3>Listar datasets disponibles en el repositorio<a class="headerlink" href="#listar-datasets-disponibles-en-el-repositorio" title="Permalink to this headline">¬∂</a></h3>
<p>Para listar los conjuntos de datos disponibles es necesario ejecutar la siguiente funci√≥n <code class="docutils literal notranslate"><span class="pre">datasets.list_datasets</span> <span class="pre">()</span></code> que pertenece a la clase <code class="docutils literal notranslate"><span class="pre">datasets</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">list_datasets</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">datasets_list</span> <span class="o">=</span> <span class="n">list_datasets</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">len</span><span class="p">(</span><span class="n">datasets_list</span><span class="p">)</span>
<span class="go">656</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dataset</span> <span class="k">for</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="n">datasets_list</span><span class="p">))</span>
<span class="go">aeslc, ag_news, ai2_arc, allocine, anli, arcd, art, billsum, blended_skill_talk, blimp, blog_authorship_corpus, bookcorpus, boolq, break_data,</span>
<span class="go">c4, cfq, civil_comments, cmrc2018, cnn_dailymail, coarse_discourse, com_qa, commonsense_qa, compguesswhat, coqa, cornell_movie_dialog, cos_e,</span>
<span class="go">cosmos_qa, crime_and_punish, csv, definite_pronoun_resolution, discofuse, docred, drop, eli5, empathetic_dialogues, eraser_multi_rc, esnli,</span>
<span class="go">event2Mind, fever, flores, fquad, gap, germeval_14, ghomasHudson/cqc, gigaword, glue, ‚Ä¶</span>
</pre></div>
</div>
<p>Otra alternativa es:</p>
<ol class="simple">
<li><p>Ir a la web <a class="reference external" href="https://huggingface.co">https://huggingface.co</a></p></li>
<li><p>Seleccionar el men√∫ Datasets: <a class="reference external" href="https://huggingface.co/datasets">https://huggingface.co/datasets</a></p></li>
<li><p>Filtrar por categor√≠a, idioma, tarea y/o licencia</p></li>
</ol>
</div>
<div class="section" id="como-cargar-datasets">
<h3>¬øC√≥mo cargar datasets?<a class="headerlink" href="#como-cargar-datasets" title="Permalink to this headline">¬∂</a></h3>
<p>Haciendo uso de la funci√≥n <code class="docutils literal notranslate"><span class="pre">load_dataset</span></code> se nos permite recuperar cualquier dataset registrado en el repositorio. Por ejemplo, el dataset <strong>MRPC</strong> que ha sido proporcionado en el √≠ndice de referencia GLUE (<a class="reference external" href="https://gluebenchmark.com/leaderboard">https://gluebenchmark.com/leaderboard</a>).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s1">&#39;glue&#39;</span><span class="p">,</span> <span class="s1">&#39;mrpc&#39;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s1">&#39;train&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>O podemos ver otro ejemplo como el de <a class="reference external" href="https://knowledge-learning.github.io/ehealthkd-2020/"><strong>eHealth-KD</strong></a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;ehealth_kd&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>No obstante, la librer√≠a <code class="docutils literal notranslate"><span class="pre">datasets</span></code> permite adem√°s <strong>cargar conjuntos de datos propios</strong> que no formen parte del repositorio. Por ejemplo:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s1">&#39;csv&#39;</span><span class="p">,</span> <span class="n">data_files</span><span class="o">=</span><span class="s1">&#39;my_file.csv&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>Para m√°s detalles sobre las distintas funciones y par√°metros permitidos para manipular datasets ver la siguiente documentaci√≥n:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://huggingface.co/docs/datasets/quicktour.html">https://huggingface.co/docs/datasets/quicktour.html</a></p></li>
</ul>
</div>
<div class="section" id="categorias-tareas-e-idiomas-de-datasets">
<h3>Categor√≠as, tareas e idiomas de datasets<a class="headerlink" href="#categorias-tareas-e-idiomas-de-datasets" title="Permalink to this headline">¬∂</a></h3>
<p><strong>9 Categor√≠as:</strong></p>
<a class="bg-primary mb-1 reference internal image-reference" href="_images/hf_dataset_categoria.jpg"><img alt="comic xkcd 2421" class="bg-primary mb-1 align-center" src="_images/hf_dataset_categoria.jpg" style="width: 300px;" /></a>
<p>Figura 1. Categor√≠as filtro de datasets</p>
<p><strong>M√°s de 134 tareas y m√°s de 194 idiomas:</strong></p>
<a class="bg-primary mb-1 reference internal image-reference" href="_images/hf_dataset_tareas_idiomas.jpg"><img alt="comic xkcd 2421" class="bg-primary mb-1 align-center" src="_images/hf_dataset_tareas_idiomas.jpg" style="width: 300px;" /></a>
<p>Figura 2. Tareas e idiomas filtro datasets</p>
</div>
</div>
<div class="section" id="repositorio-de-modelos-pre-entrenados">
<h2>Repositorio de Modelos pre-entrenados<a class="headerlink" href="#repositorio-de-modelos-pre-entrenados" title="Permalink to this headline">¬∂</a></h2>
<p>La biblioteca de Transformers permite el <strong>uso de modelos previamente entrenados</strong> para tareas de Comprensi√≥n del lenguaje natural (NLU), i.e. como analizar el sentimiento de un texto, y Generaci√≥n del lenguaje natural (NLG), i.e. como completar un mensaje con texto nuevo o traducir a otro idioma.
A groso modo listamos los modelos que nos podemos encontrar</p>
<ul class="simple">
<li><p><strong>An√°lisis de sentimiento</strong>: Conocer si un texto es positivo o negativo</p></li>
<li><p><strong>Generaci√≥n de texto</strong> (en ingl√©s): proporcionar un mensaje para el cual el modelo generar√° un texto.</p></li>
<li><p><strong>Reconocimiento de entidades nombradas</strong> (NER): Dado en una oraci√≥n de entrada se etiqueta cada palabra con la entidad que esta representa (persona, lugar, organizaci√≥n, etc.)</p></li>
<li><p><strong>Respuesta a preguntas</strong>: Teniendo en cuenta un modelo de un contexto determinado, dado un pregunta se obtiene una respuesta.</p></li>
<li><p><strong>Relleno de texto con m√°scara</strong>: Dado un texto con palabras enmascaradas (p. Ej., Reemplazado por [M√ÅSCARA]), completar los espacios en blanco.</p></li>
<li><p><strong>Resumen</strong>: Generaci√≥n de un resumen a partir de texto extenso.</p></li>
<li><p><strong>Traducci√≥n</strong>: Traducci√≥n de un texto a otro idioma.</p></li>
<li><p><strong>Extracci√≥n de caracter√≠sticas</strong>: Obtener una representaci√≥n tensorial del texto.
Tomado de https://huggingface.co/transformers/quicktour.html</p></li>
</ul>
<p><strong>Listado de tareas tal y como las podemos encontrar en el repositorio:</strong></p>
<a class="bg-primary mb-1 reference internal image-reference" href="_images/hf_modelos_tareas.jpg"><img alt="comic xkcd 2421" class="bg-primary mb-1 align-center" src="_images/hf_modelos_tareas.jpg" style="width: 300px;" /></a>
<p>Figura 3. Tareas filtro modelos</p>
<p><strong>Idiomas para los que se han entrenado los modelos:</strong></p>
<a class="bg-primary mb-1 reference internal image-reference" href="_images/hf_modelos_idiomas.jpg"><img alt="comic xkcd 2421" class="bg-primary mb-1 align-center" src="_images/hf_modelos_idiomas.jpg" style="width: 300px;" /></a>
<p>Figura 4. Idiomas filtro modelos</p>
<p>Una explicaci√≥n detallada sobre cada una de estas tareas y ejemplos de uso con Huggingface Transformer la podemos encontrar en el siguiente enlace:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://huggingface.co/transformers/task_summary.html">https://huggingface.co/transformers/task_summary.html</a></p></li>
</ul>
<p>Ejemplo de An√°lisis de Sentimientos con Huggingface Transformer:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">pipeline</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">classifier</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s1">&#39;sentiment-analysis&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">classifier</span><span class="p">(</span><span class="s1">&#39;We are very happy to show you the ü§ó Transformers library.&#39;</span><span class="p">)</span>
<span class="go">[{&#39;label&#39;: &#39;POSITIVE&#39;, &#39;score&#39;: 0.9997795224189758}]</span>
</pre></div>
</div>
<p>Si os fij√°is hemos cargado un modelo pre-entrenado a trav√©s del pipeline  <code class="docutils literal notranslate"><span class="pre">sentiment-analysis</span></code> para utilizarlo como clasificador. Este <strong>modelo</strong> se puede <strong>reentrenar</strong> a escenarios espec√≠ficos si queremos realizando un ajuste sobre un nuevo corpus. Para m√°s detalles ver la clase pr√°ctica <a class="reference external" href="https://jaspock.github.io/mtextos/bloque3_p3_SA-Transformers-Training-FineTuning.html"><code class="docutils literal notranslate"><span class="pre">bloque3_p3_SA-Transformers-Training-FineTuning</span></code></a></p>
<p>Si queremos que el pipeline sea multilingue, podemos indicar el modelo exacto que contemple un diccionario de este tipo y el pipeline lo ensamblar√° internamente. Mirad el siguiente ejemplo:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">pipeline</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">classifier</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s1">&#39;sentiment-analysis&#39;</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s1">&#39;nlptown/bert-base-multilingual-uncased-sentiment&#39;</span> <span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">classifier</span><span class="p">(</span><span class="s1">&#39;Estoy muy triste&#39;</span><span class="p">)</span>
<span class="go">[{&#39;label&#39;: &#39;1 star&#39;, &#39;score&#39;: 0.7241697907447815}]</span>
</pre></div>
</div>
<p>Para otras tareas como Rellenado de M√°scaras podemos ver como podemos simplemente indicar el tipo de tarea para que el pipeline seleccione el tipo de configuraci√≥n m√°s adecuada a esta y el modelo que queremos aplicarle. Con solo cambiar el modelo base podemos hacer esta tarea unilingue a multilingue o cambiar de idioma. Ver el ejemplo a continuaci√≥n:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelWithLMHead</span><span class="p">,</span> <span class="n">AutoTokenizer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelWithLMHead</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;mrm8488/RuPERTa-base&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;mrm8488/RuPERTa-base&quot;</span><span class="p">,</span> <span class="n">do_lower_case</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">pipeline</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">pipeline_fill_mask</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s2">&quot;fill-mask&quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">pipeline_fill_mask</span><span class="p">(</span><span class="s2">&quot;Espa√±a es un pa√≠s muy &lt;mask&gt; en la UE&quot;</span><span class="p">)</span>

<span class="go">[{&#39;score&#39;: 0.19951821863651276,</span>
<span class="go">  &#39;sequence&#39;: &#39;Espa√±a es un pa√≠s muy importante en la UE&#39;,</span>
<span class="go">  &#39;token&#39;: 1560,</span>
<span class="go">  &#39;token_str&#39;: &#39; importante&#39;},</span>
<span class="go"> {&#39;score&#39;: 0.04137842729687691,</span>
<span class="go">  &#39;sequence&#39;: &#39;Espa√±a es un pa√≠s muy grande en la UE&#39;,</span>
<span class="go">  &#39;token&#39;: 2741,</span>
<span class="go">  &#39;token_str&#39;: &#39; grande&#39;},</span>
<span class="go"> {&#39;score&#39;: 0.029216745868325233,</span>
<span class="go">  &#39;sequence&#39;: &#39;Espa√±a es un pa√≠s muy peque√±o en la UE&#39;,</span>
<span class="go">  &#39;token&#39;: 2948,</span>
<span class="go">  &#39;token_str&#39;: &#39; peque√±o&#39;},</span>
<span class="go"> {&#39;score&#39;: 0.02563760057091713,</span>
<span class="go">  &#39;sequence&#39;: &#39;Espa√±a es un pa√≠s muy popular en la UE&#39;,</span>
<span class="go">  &#39;token&#39;: 5782,</span>
<span class="go">  &#39;token_str&#39;: &#39; popular&#39;},</span>
<span class="go"> {&#39;score&#39;: 0.022264542058110237,</span>
<span class="go">  &#39;sequence&#39;: &#39;Espa√±a es un pa√≠s muy antiguo en la UE&#39;,</span>
<span class="go">  &#39;token&#39;: 5240,</span>
<span class="go">  &#39;token_str&#39;: &#39; antiguo&#39;}]</span>
</pre></div>
</div>
<div class="section" id="listado-de-pipelines">
<h3>Listado de Pipelines<a class="headerlink" href="#listado-de-pipelines" title="Permalink to this headline">¬∂</a></h3>
<p>En Huggingface podemos encontrar una serie de Pipelines ya preparados para enfrentar tareas concretas a los cuales les podemos suministrar distintos modelos y tokenizadores transformes. Ver ejemplos: <a class="reference external" href="https://huggingface.co/transformers/main_classes/pipelines.html">https://huggingface.co/transformers/main_classes/pipelines.html</a></p>
</div>
<div class="section" id="como-buscar-y-reutilizar-modelos-pre-entrenados-en-la-plataforma">
<h3>¬øC√≥mo buscar y reutilizar modelos pre-entrenados en la plataforma?<a class="headerlink" href="#como-buscar-y-reutilizar-modelos-pre-entrenados-en-la-plataforma" title="Permalink to this headline">¬∂</a></h3>
<p>A continuaci√≥n, se listan los pasos a seguir:</p>
<ol class="simple">
<li><p>Dirigirse al repositorio <a class="reference external" href="https://huggingface.co/">https://huggingface.co/</a></p></li>
<li><p>Seleccionar el men√∫ <code class="docutils literal notranslate"><span class="pre">models</span></code> que nos llevar√° a <a class="reference external" href="https://huggingface.co/models">https://huggingface.co/models</a></p></li>
<li><p>Filtrar el listado de modelos seg√∫n la tarea, idioma, librer√≠a (Pytorch o TensorFlow), dataset sobre el que fue entrenado, o licencia. Por ejemplo:  tarea <code class="docutils literal notranslate"><span class="pre">Text</span> <span class="pre">Classification</span></code>; idioma <code class="docutils literal notranslate"><span class="pre">es</span></code>.</p></li>
<li><p>Elegir un modelo de la lista. Por ejemplo: <code class="docutils literal notranslate"><span class="pre">bert-base-multilingual-uncased-sentiment</span></code></p></li>
<li><p>Obtendremos la documentaci√≥n necesaria para utilizar el modelo.</p></li>
</ol>
<p><strong>Conociendo el nombre del modelo</strong> a utilizar entonces podemos <strong>hacer uso</strong> de este a trav√©s de la librer√≠a <strong>Transformer</strong>.
En la propia documentaci√≥n se aporta el <strong>c√≥digo de ejemplo</strong> para hacer uso del modelo y en algunos casos una <a class="reference external" href="https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment"><strong>interfaz para probarlo</strong></a>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span><span class="p">)</span>  <span class="c1"># cargando el toquenizador basado en el modelo preentrenado</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span><span class="p">)</span> <span class="c1"># cargando del modelo preentrenado</span>
</pre></div>
</div>
</div>
<div class="section" id="configuraciones-de-modelos-trasnformers">
<h3>Configuraciones de modelos trasnformers<a class="headerlink" href="#configuraciones-de-modelos-trasnformers" title="Permalink to this headline">¬∂</a></h3>
<p>Los <strong>modelos pre-entrenados</strong> que se brindan en el repositorio se <strong>basan</strong> en alguna de las <strong>arquitecturas Transformers</strong> descrita en la documentaci√≥n del repositorio (<a class="reference external" href="https://huggingface.co/docs">https://huggingface.co/docs</a>).
Si tomamos como referencia la arquitectura de modelo Transformer <a class="reference external" href="https://huggingface.co/transformers/model_doc/distilbert.html#overview">DistilBERT</a> podemos conocer c√≥mo <strong>gestionar</strong> los distintos <strong>par√°metros</strong>, <a class="reference external" href="https://huggingface.co/transformers/model_doc/distilbert.html#distilbertconfig"><strong>configuraciones de red neuronal</strong></a>, <a class="reference external" href="https://huggingface.co/transformers/model_doc/distilbert.html#distilberttokenizer"><strong>tokenizador</strong></a> y <strong>ejemplos</strong> para cada tipo de tarea.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># !pip install transformers</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">DistilBertTokenizer</span><span class="p">,</span> <span class="n">DistilBertModel</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">DistilBertTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;distilbert-base-uncased&#39;</span><span class="p">)</span> <span class="c1"># cargando de toquenizador basado en el modelo preentrenado</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">DistilBertModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;distilbert-base-uncased&#39;</span><span class="p">)</span> <span class="c1"># cargando el modelo preentrenado</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot;Hello, my dog is cute&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">last_hidden_states</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">last_hidden_state</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">last_hidden_states</span><span class="p">)</span>

<span class="go">tensor([[[-1.8296e-01, -7.4054e-02,  5.0267e-02,  ..., -1.1261e-01,</span>
<span class="go">           4.4493e-01,  4.0941e-01],</span>
<span class="go">         [ 7.0631e-04,  1.4825e-01,  3.4328e-01,  ..., -8.6039e-02,</span>
<span class="go">           6.9475e-01,  4.3353e-02],</span>
<span class="go">         [-5.0721e-01,  5.3086e-01,  3.7163e-01,  ..., -5.6287e-01,</span>
<span class="go">           1.3756e-01,  2.8475e-01],</span>
<span class="go">         ...,</span>
<span class="go">         [-4.2251e-01,  5.7314e-02,  2.4338e-01,  ..., -1.5223e-01,</span>
<span class="go">           2.4462e-01,  6.4155e-01],</span>
<span class="go">         [-4.9384e-01, -1.8895e-01,  1.2641e-01,  ...,  6.3241e-02,</span>
<span class="go">           3.6913e-01, -5.8252e-02],</span>
<span class="go">         [ 8.3269e-01,  2.4948e-01, -4.5440e-01,  ...,  1.1998e-01,</span>
<span class="go">          -3.9257e-01, -2.7785e-01]]], grad_fn=&lt;NativeLayerNormBackward&gt;)</span>

</pre></div>
</div>
<p>Es importante conocer que las <strong>configuraciones</strong> de modelos Transformer ya <strong>cuentan</strong> con <strong>modelos base pre-entrenados</strong>. En el caso de <code class="docutils literal notranslate"><span class="pre">DistilBERT</span></code> podemos encontrar <code class="docutils literal notranslate"><span class="pre">distilbert-base-uncased</span></code>.</p>
</div>
</div>
<div class="section" id="bibliografia">
<h2>Bibliograf√≠a<a class="headerlink" href="#bibliografia" title="Permalink to this headline">¬∂</a></h2>
<p>[1] <a class="reference external" href="https://huggingface.co/">https://huggingface.co/</a></p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Universitat d'Alacant<br/>
    
        &copy; Copyright 2022.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>